ЗАДАЧА: Исчерпывающий отчет по всем метрикам микросервисов  в ходе нагрузочного тестирования

ИСХОДНЫЕ ДАННЫЕ:
- Все данные по среднему времени запросов (rate(nsi_query_seconds_sum)/rate(nsi_query_seconds_count))
- Все данные по количеству запросов (rate(nsi_query_seconds_count))
- Суммарный RPS для выявления максимальной производительности 
- Все другие доступные метрики по микросервисам


РЕКОМЕНДУЕМЫЕ ОРИЕНТИРЫ:
- Время отклика (latency P95): норма < 200 мс; предупреждение 200–500 мс; критично > 500 мс
- Суммарный RPS для выявления максимальной производительности : норма > 1000 RPS; предупреждение > 750 RPS; критично > 500 RPS

ТРЕБОВАНИЯ К АНАЛИЗУ:
1. Проанализировать ВСЕ доступные метрики по ВСЕМ микросервисам
2. По каждой метрике и каждому микросервису предоставить:
   - Полный диапазон значений (мин/макс/среднее)
   - Все временные интервалы изменений
   - Сравнительный анализ между всеми сервисами
   - Соответствие рекомендуемым SLA

3. Выделить в анализе:
   - Соответствие целевым ориентирам по latency для каждого микросервиса
   - Указать RPS, при котором впервые зафиксировано превышение порога по latency, и интервал (start–end)
   - Определить пиковую нагрузку по суммарному RPS (если возможно агрегировать RPS по всем сервисам из предоставленных данных)
   - Корреляции между latency и RPS для каждого сервиса

СТРУКТУРА ОТВЕТА:
1. Анализ времени запроса (latency)
   • Полный анализ по ВСЕМ микросервисам без исключения
   • Все значения с указанием времени для каждого сервиса
   • Исчерпывающее сравнение между всеми сервисами
   • Соответствие целевым SLA по времени отклика

2. Анализ количества запросов (RPS)
   • Детальный анализ RPS по всем микросервисам
   • Все пиковые значения с точным временем
   • Полная динамика изменений для каждого сервиса
   • Сравнение с максимальной пропускной способностью

3. Связь нагрузки и латенси
   • Исчерпывающий анализ корреляций для каждого сервиса
   • Все случаи зависимости времени ответа от нагрузки
   • Полное описание поведения сервисов при различных нагрузках
   • Оценка соответствия SLA при различных уровнях нагрузки

4. Итоговые выводы
   • Обобщение по всем проанализированным метрикам
   • Сравнительный анализ всех микросервисов
   • Конкретные рекомендации для каждого сервиса
   • Общая оценка соответствия SLA и предложения по оптимизации

ВАЖНО:
1. НЕ ПРИДУМЫВАТЬ ДАННЫХ. Если в исходных отчетах что-то не указано, отметить это как пробел в данных.
2. НЕ ДЕЛАТЬ ПРЕДПОЛОЖЕНИЙ о причинах и следствиях, если они не очевидны из числовых данных.
3. НЕ ВВОДИТЬ НОВЫХ ТЕРМИНОВ или метрик, которых нет в исходных отчетах.
4. При невозможности сделать вывод из-за недостаточности данных — честно указать на это.
5. Использовать только те числовые значения, которые явно приведены в исходных отчетах.
6. Включите в анализ данные по всем микросервисам, даже если некоторые из них имеют незначительные показатели. Не пропускайте никакие метрики.


ФОРМАТ ОТВЕТА (ВСЕ ТЕКСТОВЫЕ ПОЛЯ — НА РУССКОМ):
- Отвечайте строго в JSON со схемой: {verdict, confidence, findings[], recommended_actions[]}.
- Поле verdict ДОЛЖНО принимать только одно из: "Успешно" | "Есть риски" | "Провал" | "Недостаточно данных".
- Если данных недостаточно, верните verdict: "Недостаточно данных" и укажите причину в findings.
- Для каждого findings в evidence укажите: microservice, метрику, интервал отклонения start–end, peak_time и RPS в момент превышения.
- Если возможно по данным агрегировать суммарный RPS (по всем сервисам), добавьте поле peak_performance: {max_rps, max_time, drop_time, method="max_step_before_drop"}.

ПРИМЕР ОТВЕТА (JSON):
```json
{
  "verdict": "Успешно",
  "confidence": 0.74,
  "findings": [
    "Среднее время ответа стабильно, P95 < 250мс на всех сервисах",
    {"summary": "RPS вырос на 30% без деградации latency на micro-registry-nsi"}
  ],
  "recommended_actions": [
    "Добавить алерт P95>300мс для всех сервисов",
    "Проверить лимиты CPU для micro-address-search-node"
  ]
}
```